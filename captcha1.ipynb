{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Project File:\n",
    "\n",
    "Shell for the CAPTCHA Cracking Challenge\n",
    "\n",
    "There are 8501 training images and a secret number of test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 09:14:17.045309: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['44', 'uurhhh', 'jpeg']\n",
      "UURHHH\n",
      "44.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches as ptc \n",
    "import math\n",
    "import random\n",
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "# Define function for converting text to one-hot numerical encoding\n",
    "\n",
    "def OneHotConverter(textstring, dictionary): # Needs to be a reverse dictionary\n",
    "\n",
    "    ans = np.zeros((6, 21))\n",
    "    for i in range(6):\n",
    "        char = textstring[i].upper()\n",
    "        num = dict2[char]\n",
    "        ans[i][num] = 1\n",
    "    return ans \n",
    "\n",
    "\n",
    "\n",
    "# Define dictionaries for encoding/decoding\n",
    "dict1 = {0:'2', 1:'6', 2:'A', 3:'B', 4:'C', 5:'D', 6:'E', 7:'F', 8:'G', 9:'H', 10:'K', 11:'M', \n",
    "              12:'N', 13:'P', 14:'R', 15:'S', 16:'T', 17:'U', 18:'V', 19:'X', 20:'Z'}\n",
    "dict2 = {v: k for k, v in dict1.items()}\n",
    "\n",
    "\n",
    "\n",
    "trainfiles2 = os.listdir('./traindata/')\n",
    "trainfiles = [f for f in trainfiles2 if os.path.isfile('.' +'/traindata/' + f)] #Filtering only the files.\n",
    "valfiles2 = os.listdir('./valdata/')\n",
    "valfiles = [f for f in valfiles2 if os.path.isfile('.' +'/valdata/' + f)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "random.shuffle(trainfiles)\n",
    "numtrain = len(trainfiles)\n",
    "numval = len(valfiles)\n",
    "\n",
    "train_images = np.zeros((numtrain,250,50))\n",
    "train_labels = np.zeros((numtrain,6,21))\n",
    "train_labels1 = np.zeros((numtrain, 21))\n",
    "train_labels2 = np.zeros((numtrain, 21))\n",
    "train_labels3 = np.zeros((numtrain, 21))\n",
    "train_labels4 = np.zeros((numtrain, 21))\n",
    "train_labels5 = np.zeros((numtrain, 21))\n",
    "train_labels6 = np.zeros((numtrain, 21))\n",
    "train_numlist = np.zeros((numtrain))\n",
    "train_letters = ['     '] * numtrain\n",
    "\n",
    "val_images = np.zeros((numval,250,50))\n",
    "val_labels = np.zeros((numval,6,21))\n",
    "val_labels1 = np.zeros((numval, 21))\n",
    "val_labels2 = np.zeros((numval, 21))\n",
    "val_labels3 = np.zeros((numval, 21))\n",
    "val_labels4 = np.zeros((numval, 21))\n",
    "val_labels5 = np.zeros((numval, 21))\n",
    "val_labels6 = np.zeros((numval, 21))\n",
    "val_numlist = np.zeros((numval))\n",
    "val_letters = ['     '] * numval\n",
    "\n",
    "\n",
    "# Define training set\n",
    "for i in range(numtrain):\n",
    "    img = Image.open('./traindata/' + trainfiles[i]).convert('L')\n",
    "    data = np.transpose(np.asarray(img)) / 255\n",
    "    train_images[i] = data\n",
    "    train_numlist[i] = re.split(r\"[_.]\", trainfiles[i])[0]\n",
    "    temp = re.split(r\"[_.]\", trainfiles[i])\n",
    "    train_labels[i] = OneHotConverter(temp[1], dict2)\n",
    "    train_labels1[i] = train_labels[i][0]\n",
    "    train_labels2[i] = train_labels[i][1]\n",
    "    train_labels3[i] = train_labels[i][2]\n",
    "    train_labels4[i] = train_labels[i][3]\n",
    "    train_labels5[i] = train_labels[i][4]\n",
    "    train_labels6[i] = train_labels[i][5]\n",
    "    train_letters[i] = temp[1].upper()\n",
    "\n",
    "# Define validation set\n",
    "for i in range(numval):\n",
    "    img = Image.open('./valdata/' + valfiles[i]).convert('L')\n",
    "    data = np.transpose(np.asarray(img)) / 255\n",
    "    val_images[i] = data\n",
    "    val_numlist[i] = re.split(r\"[_.]\", valfiles[i])[0]\n",
    "    temp = re.split(r\"[_.]\", valfiles[i])\n",
    "    val_labels[i] = OneHotConverter(temp[1], dict2)\n",
    "    val_labels1[i] = val_labels[i][0]\n",
    "    val_labels2[i] = val_labels[i][1]\n",
    "    val_labels3[i] = val_labels[i][2]\n",
    "    val_labels4[i] = val_labels[i][3]\n",
    "    val_labels5[i] = val_labels[i][4]\n",
    "    val_labels6[i] = val_labels[i][5]\n",
    "    val_letters[i] = temp[1].upper()\n",
    "\n",
    "# Below is an example of how you can get the info from a train or validation file\n",
    "print(re.split(r\"[_.]\", trainfiles[0]))\n",
    "\n",
    "print(train_letters[0])\n",
    "print(train_numlist[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network for Captcha Recognition\n",
    "\n",
    "This network is designed for efficient captcha recognition. The choice of architecture and layers is aimed at balancing model complexity and computational demands, allowing for effective training on a standard computer and quick experimentation.\n",
    "\n",
    "## Network Layers\n",
    "\n",
    "### Input Layer\n",
    "- The input layer takes images of size 250x50 pixels with a single channel (grayscale). This size is sufficient to capture the details needed for captcha recognition.\n",
    "\n",
    "### Convolutional Layers (Conv2D)\n",
    "- Convolutional layers are used to extract features from the input image. Filters applied in these layers help in identifying patterns such as edges, shapes, and other features for recognizing characters in captchas.\n",
    "\n",
    "### Batch Normalization Layers\n",
    "- Batch normalization is applied after convolutional layers. It stabilizes and accelerates the training process by normalizing the outputs.\n",
    "\n",
    "### Max Pooling Layers\n",
    "- Max pooling reduces the spatial dimensions of the output from the convolutional layers. This downsampling helps to reduce computational load and overfitting by abstracting the features.\n",
    "\n",
    "### Dropout Layers\n",
    "- Dropout layers are crucial for preventing overfitting. They randomly deactivate a portion of the neurons (25% in this case), forcing the network to learn redundant representations and enhancing its generalization capability.\n",
    "\n",
    "### Flatten Layer\n",
    "- The flatten layer is used to convert the multi-dimensional output from the convolutional and pooling layers into a one-dimensional array. This is necessary before passing the data to the fully connected (dense) layers.\n",
    "\n",
    "## Model Choice purpose\n",
    "- The chosen model architecture, with fewer parameters, is optimized to run efficiently on a standard computer. This approach enables practical application to real-life captcha problems and achieves good accuracy in a relatively short time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model.  \n",
    "\n",
    "Input layer: 250x50 pixel images in grayscale (0 to 1 values)\n",
    "\n",
    "ADD NETWORK HERE\n",
    "\n",
    "\n",
    "Final activation function needs to be softmax\n",
    "Output: 6*21 matrix, each of the 6 21 entry rows is a confidence vector for the given character\n",
    "Loss functions: 6 copies of cross-entropy for the 6 different characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " Input (InputLayer)          [(None, 250, 50, 1)]         0         []                            \n",
      "                                                                                                  \n",
      " Convolution (Conv2D)        (None, 250, 50, 32)          320       ['Input[0][0]']               \n",
      "                                                                                                  \n",
      " BatchNormalization1 (Batch  (None, 250, 50, 32)          128       ['Convolution[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " MaxPooling1 (MaxPooling2D)  (None, 124, 24, 32)          0         ['BatchNormalization1[0][0]'] \n",
      "                                                                                                  \n",
      " Convolution1 (Conv2D)       (None, 124, 24, 64)          18496     ['MaxPooling1[0][0]']         \n",
      "                                                                                                  \n",
      " BatchNormalization2 (Batch  (None, 124, 24, 64)          256       ['Convolution1[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Dropout1 (Dropout)          (None, 124, 24, 64)          0         ['BatchNormalization2[0][0]'] \n",
      "                                                                                                  \n",
      " Convolution2 (Conv2D)       (None, 124, 24, 128)         32896     ['Dropout1[0][0]']            \n",
      "                                                                                                  \n",
      " BatchNormalization3 (Batch  (None, 124, 24, 128)         512       ['Convolution2[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " MaxPooling2 (MaxPooling2D)  (None, 61, 11, 128)          0         ['BatchNormalization3[0][0]'] \n",
      "                                                                                                  \n",
      " Dropout2 (Dropout)          (None, 61, 11, 128)          0         ['MaxPooling2[0][0]']         \n",
      "                                                                                                  \n",
      " Convolution3 (Conv2D)       (None, 61, 11, 128)          65664     ['Dropout2[0][0]']            \n",
      "                                                                                                  \n",
      " BatchNormalization4 (Batch  (None, 61, 11, 128)          512       ['Convolution3[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " MaxPooling3 (MaxPooling2D)  (None, 30, 5, 128)           0         ['BatchNormalization4[0][0]'] \n",
      "                                                                                                  \n",
      " Dropout3 (Dropout)          (None, 30, 5, 128)           0         ['MaxPooling3[0][0]']         \n",
      "                                                                                                  \n",
      " Convolution4 (Conv2D)       (None, 30, 5, 128)           65664     ['Dropout3[0][0]']            \n",
      "                                                                                                  \n",
      " BatchNormalization5 (Batch  (None, 30, 5, 128)           512       ['Convolution4[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " MaxPooling4 (MaxPooling2D)  (None, 14, 2, 128)           0         ['BatchNormalization5[0][0]'] \n",
      "                                                                                                  \n",
      " Dropout4 (Dropout)          (None, 14, 2, 128)           0         ['MaxPooling4[0][0]']         \n",
      "                                                                                                  \n",
      " Flatten (Flatten)           (None, 3584)                 0         ['Dropout4[0][0]']            \n",
      "                                                                                                  \n",
      " Char_1 (Dense)              (None, 21)                   75285     ['Flatten[0][0]']             \n",
      "                                                                                                  \n",
      " Char_2 (Dense)              (None, 21)                   75285     ['Flatten[0][0]']             \n",
      "                                                                                                  \n",
      " Char_3 (Dense)              (None, 21)                   75285     ['Flatten[0][0]']             \n",
      "                                                                                                  \n",
      " Char_4 (Dense)              (None, 21)                   75285     ['Flatten[0][0]']             \n",
      "                                                                                                  \n",
      " Char_5 (Dense)              (None, 21)                   75285     ['Flatten[0][0]']             \n",
      "                                                                                                  \n",
      " Char_6 (Dense)              (None, 21)                   75285     ['Flatten[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 636670 (2.43 MB)\n",
      "Trainable params: 635710 (2.43 MB)\n",
      "Non-trainable params: 960 (3.75 KB)\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "inputlayer = tf.keras.Input(shape=(250, 50, 1), name=\"Input\")\n",
    "\n",
    "convlayer = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', name=\"Convolution\")(inputlayer)\n",
    "batch_norm1 = tf.keras.layers.BatchNormalization(name=\"BatchNormalization1\")(convlayer)\n",
    "max_pool1 = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name=\"MaxPooling1\")(batch_norm1)\n",
    "\n",
    "convlayer1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', name=\"Convolution1\")(max_pool1)\n",
    "batch_norm2 = tf.keras.layers.BatchNormalization(name=\"BatchNormalization2\")(convlayer1)\n",
    "dropout1 = tf.keras.layers.Dropout(0.25, name=\"Dropout1\")(batch_norm2)\n",
    "\n",
    "\n",
    "convlayer2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(2, 2), padding='same', name=\"Convolution2\")(dropout1)\n",
    "batch_norm3 = tf.keras.layers.BatchNormalization(name=\"BatchNormalization3\")(convlayer2)\n",
    "max_pool2 = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name=\"MaxPooling2\")(batch_norm3)\n",
    "\n",
    "dropout2 = tf.keras.layers.Dropout(0.25, name=\"Dropout2\")(max_pool2)\n",
    "\n",
    "convlayer3 = tf.keras.layers.Conv2D(filters=128, kernel_size=(2, 2), padding='same', name=\"Convolution3\")(dropout2)\n",
    "batch_norm4 = tf.keras.layers.BatchNormalization(name=\"BatchNormalization4\")(convlayer3)\n",
    "max_pool3 = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name=\"MaxPooling3\")(batch_norm4)\n",
    "\n",
    "dropout3 = tf.keras.layers.Dropout(0.25, name=\"Dropout3\")(max_pool3)\n",
    "\n",
    "convlayer4 = tf.keras.layers.Conv2D(filters=128, kernel_size=(2, 2), padding='same', name=\"Convolution4\")(dropout3)\n",
    "batch_norm5 = tf.keras.layers.BatchNormalization(name=\"BatchNormalization5\")(convlayer4)\n",
    "max_pool4 = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name=\"MaxPooling4\")(batch_norm5)\n",
    "\n",
    "dropout4 = tf.keras.layers.Dropout(0.25, name=\"Dropout4\")(max_pool4)\n",
    "\n",
    "\n",
    "flatlayer = tf.keras.layers.Flatten(name=\"Flatten\")(dropout4)\n",
    "\n",
    "char1 = tf.keras.layers.Dense(21, activation='softmax', name='Char_1')(flatlayer)\n",
    "char2 = tf.keras.layers.Dense(21, activation='softmax', name='Char_2')(flatlayer)\n",
    "char3 = tf.keras.layers.Dense(21, activation='softmax', name='Char_3')(flatlayer)\n",
    "char4 = tf.keras.layers.Dense(21, activation='softmax', name='Char_4')(flatlayer)\n",
    "\n",
    "char5 = tf.keras.layers.Dense(21, activation='softmax', name='Char_5')(flatlayer)\n",
    "char6 = tf.keras.layers.Dense(21, activation='softmax', name='Char_6')(flatlayer)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputlayer, outputs=[char1, char2, char3, char4, char5, char6])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss={\n",
    "        \"Char_1\": tf.keras.losses.CategoricalCrossentropy(),\n",
    "        \"Char_2\": tf.keras.losses.CategoricalCrossentropy(),\n",
    "        \"Char_3\": tf.keras.losses.CategoricalCrossentropy(),\n",
    "        \"Char_4\": tf.keras.losses.CategoricalCrossentropy(),\n",
    "        \"Char_5\": tf.keras.losses.CategoricalCrossentropy(),\n",
    "        \"Char_6\": tf.keras.losses.CategoricalCrossentropy()\n",
    "    },\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "tf.keras.utils.plot_model(model, \"model.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Size Selection\n",
    "\n",
    "## Batch Size: 64\n",
    "- The batch size for training is set to 64. This choice is a balance between computational efficiency and model performance. Smaller batch sizes can offer a regularizing effect and can lead to faster convergence. However, they can also make the training process noisier.\n",
    "- By choosing a batch size of 64, we ensure that the model training is computationally feasible on a standard computer without compromising much on the learning stability and performance. It allows for efficient use of memory resources while providing enough data for each iteration to accurately estimate the gradient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "133/133 [==============================] - 31s 233ms/step - loss: 16.9698 - Char_1_loss: 2.7648 - Char_2_loss: 2.8069 - Char_3_loss: 2.8476 - Char_4_loss: 2.8455 - Char_5_loss: 2.8665 - Char_6_loss: 2.8385 - Char_1_accuracy: 0.1782 - Char_2_accuracy: 0.1673 - Char_3_accuracy: 0.1560 - Char_4_accuracy: 0.1588 - Char_5_accuracy: 0.1522 - Char_6_accuracy: 0.1600 - val_loss: 35.6482 - val_Char_1_loss: 5.2280 - val_Char_2_loss: 7.2740 - val_Char_3_loss: 6.0144 - val_Char_4_loss: 6.1942 - val_Char_5_loss: 6.2885 - val_Char_6_loss: 4.6492 - val_Char_1_accuracy: 0.0360 - val_Char_2_accuracy: 0.0320 - val_Char_3_accuracy: 0.0520 - val_Char_4_accuracy: 0.0360 - val_Char_5_accuracy: 0.0480 - val_Char_6_accuracy: 0.0940\n",
      "Epoch 2/50\n",
      "133/133 [==============================] - 32s 243ms/step - loss: 11.3371 - Char_1_loss: 1.7966 - Char_2_loss: 1.8991 - Char_3_loss: 1.9241 - Char_4_loss: 1.9217 - Char_5_loss: 1.9639 - Char_6_loss: 1.8317 - Char_1_accuracy: 0.4171 - Char_2_accuracy: 0.3872 - Char_3_accuracy: 0.3805 - Char_4_accuracy: 0.3801 - Char_5_accuracy: 0.3628 - Char_6_accuracy: 0.4012 - val_loss: 33.1279 - val_Char_1_loss: 4.2195 - val_Char_2_loss: 5.9961 - val_Char_3_loss: 6.7548 - val_Char_4_loss: 6.3559 - val_Char_5_loss: 5.8322 - val_Char_6_loss: 3.9694 - val_Char_1_accuracy: 0.1980 - val_Char_2_accuracy: 0.0480 - val_Char_3_accuracy: 0.0920 - val_Char_4_accuracy: 0.0760 - val_Char_5_accuracy: 0.0740 - val_Char_6_accuracy: 0.1280\n",
      "Epoch 3/50\n",
      "133/133 [==============================] - 32s 241ms/step - loss: 6.7674 - Char_1_loss: 1.0348 - Char_2_loss: 1.1508 - Char_3_loss: 1.1791 - Char_4_loss: 1.1841 - Char_5_loss: 1.2114 - Char_6_loss: 1.0071 - Char_1_accuracy: 0.6582 - Char_2_accuracy: 0.6195 - Char_3_accuracy: 0.6157 - Char_4_accuracy: 0.6135 - Char_5_accuracy: 0.6040 - Char_6_accuracy: 0.6749 - val_loss: 24.1053 - val_Char_1_loss: 3.0018 - val_Char_2_loss: 4.5274 - val_Char_3_loss: 5.1132 - val_Char_4_loss: 4.2003 - val_Char_5_loss: 4.3813 - val_Char_6_loss: 2.8813 - val_Char_1_accuracy: 0.2720 - val_Char_2_accuracy: 0.1360 - val_Char_3_accuracy: 0.1500 - val_Char_4_accuracy: 0.1520 - val_Char_5_accuracy: 0.1600 - val_Char_6_accuracy: 0.2600\n",
      "Epoch 4/50\n",
      "133/133 [==============================] - 32s 243ms/step - loss: 4.1014 - Char_1_loss: 0.5657 - Char_2_loss: 0.6980 - Char_3_loss: 0.7108 - Char_4_loss: 0.7451 - Char_5_loss: 0.7871 - Char_6_loss: 0.5947 - Char_1_accuracy: 0.8265 - Char_2_accuracy: 0.7801 - Char_3_accuracy: 0.7754 - Char_4_accuracy: 0.7632 - Char_5_accuracy: 0.7524 - Char_6_accuracy: 0.8120 - val_loss: 12.6759 - val_Char_1_loss: 1.6240 - val_Char_2_loss: 2.0071 - val_Char_3_loss: 2.9515 - val_Char_4_loss: 2.4457 - val_Char_5_loss: 2.1625 - val_Char_6_loss: 1.4851 - val_Char_1_accuracy: 0.5300 - val_Char_2_accuracy: 0.4560 - val_Char_3_accuracy: 0.2540 - val_Char_4_accuracy: 0.3720 - val_Char_5_accuracy: 0.4060 - val_Char_6_accuracy: 0.5600\n",
      "Epoch 5/50\n",
      "133/133 [==============================] - 31s 236ms/step - loss: 2.8498 - Char_1_loss: 0.3726 - Char_2_loss: 0.4945 - Char_3_loss: 0.4983 - Char_4_loss: 0.5260 - Char_5_loss: 0.5788 - Char_6_loss: 0.3796 - Char_1_accuracy: 0.8891 - Char_2_accuracy: 0.8425 - Char_3_accuracy: 0.8430 - Char_4_accuracy: 0.8299 - Char_5_accuracy: 0.8146 - Char_6_accuracy: 0.8830 - val_loss: 6.8078 - val_Char_1_loss: 1.0078 - val_Char_2_loss: 1.2125 - val_Char_3_loss: 1.4039 - val_Char_4_loss: 1.1597 - val_Char_5_loss: 1.2537 - val_Char_6_loss: 0.7702 - val_Char_1_accuracy: 0.6960 - val_Char_2_accuracy: 0.5960 - val_Char_3_accuracy: 0.5960 - val_Char_4_accuracy: 0.6520 - val_Char_5_accuracy: 0.6540 - val_Char_6_accuracy: 0.7600\n",
      "Epoch 6/50\n",
      "133/133 [==============================] - 31s 236ms/step - loss: 2.1513 - Char_1_loss: 0.2842 - Char_2_loss: 0.3937 - Char_3_loss: 0.3851 - Char_4_loss: 0.4033 - Char_5_loss: 0.4111 - Char_6_loss: 0.2739 - Char_1_accuracy: 0.9148 - Char_2_accuracy: 0.8781 - Char_3_accuracy: 0.8812 - Char_4_accuracy: 0.8748 - Char_5_accuracy: 0.8721 - Char_6_accuracy: 0.9195 - val_loss: 5.3213 - val_Char_1_loss: 0.7817 - val_Char_2_loss: 0.5889 - val_Char_3_loss: 1.0626 - val_Char_4_loss: 1.0466 - val_Char_5_loss: 1.0428 - val_Char_6_loss: 0.7988 - val_Char_1_accuracy: 0.7620 - val_Char_2_accuracy: 0.8020 - val_Char_3_accuracy: 0.6760 - val_Char_4_accuracy: 0.6920 - val_Char_5_accuracy: 0.7160 - val_Char_6_accuracy: 0.7560\n",
      "Epoch 7/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 1.6524 - Char_1_loss: 0.1997 - Char_2_loss: 0.3017 - Char_3_loss: 0.2956 - Char_4_loss: 0.3233 - Char_5_loss: 0.3336 - Char_6_loss: 0.1986 - Char_1_accuracy: 0.9425 - Char_2_accuracy: 0.9068 - Char_3_accuracy: 0.9078 - Char_4_accuracy: 0.8990 - Char_5_accuracy: 0.8993 - Char_6_accuracy: 0.9445 - val_loss: 3.6106 - val_Char_1_loss: 0.5135 - val_Char_2_loss: 0.7253 - val_Char_3_loss: 0.6361 - val_Char_4_loss: 0.5063 - val_Char_5_loss: 0.8044 - val_Char_6_loss: 0.4250 - val_Char_1_accuracy: 0.8400 - val_Char_2_accuracy: 0.7680 - val_Char_3_accuracy: 0.7980 - val_Char_4_accuracy: 0.8200 - val_Char_5_accuracy: 0.7620 - val_Char_6_accuracy: 0.8860\n",
      "Epoch 8/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 1.3437 - Char_1_loss: 0.1683 - Char_2_loss: 0.2528 - Char_3_loss: 0.2345 - Char_4_loss: 0.2589 - Char_5_loss: 0.2716 - Char_6_loss: 0.1575 - Char_1_accuracy: 0.9507 - Char_2_accuracy: 0.9204 - Char_3_accuracy: 0.9294 - Char_4_accuracy: 0.9219 - Char_5_accuracy: 0.9158 - Char_6_accuracy: 0.9546 - val_loss: 1.5336 - val_Char_1_loss: 0.1769 - val_Char_2_loss: 0.2294 - val_Char_3_loss: 0.3077 - val_Char_4_loss: 0.3087 - val_Char_5_loss: 0.3645 - val_Char_6_loss: 0.1464 - val_Char_1_accuracy: 0.9360 - val_Char_2_accuracy: 0.9300 - val_Char_3_accuracy: 0.9020 - val_Char_4_accuracy: 0.9040 - val_Char_5_accuracy: 0.8780 - val_Char_6_accuracy: 0.9520\n",
      "Epoch 9/50\n",
      "133/133 [==============================] - 32s 237ms/step - loss: 1.1006 - Char_1_loss: 0.1405 - Char_2_loss: 0.2024 - Char_3_loss: 0.1953 - Char_4_loss: 0.2221 - Char_5_loss: 0.2161 - Char_6_loss: 0.1242 - Char_1_accuracy: 0.9617 - Char_2_accuracy: 0.9382 - Char_3_accuracy: 0.9412 - Char_4_accuracy: 0.9328 - Char_5_accuracy: 0.9319 - Char_6_accuracy: 0.9679 - val_loss: 2.0140 - val_Char_1_loss: 0.3301 - val_Char_2_loss: 0.3472 - val_Char_3_loss: 0.3673 - val_Char_4_loss: 0.2922 - val_Char_5_loss: 0.4180 - val_Char_6_loss: 0.2592 - val_Char_1_accuracy: 0.9020 - val_Char_2_accuracy: 0.8980 - val_Char_3_accuracy: 0.8860 - val_Char_4_accuracy: 0.9040 - val_Char_5_accuracy: 0.8720 - val_Char_6_accuracy: 0.9160\n",
      "Epoch 10/50\n",
      "133/133 [==============================] - 32s 238ms/step - loss: 0.9131 - Char_1_loss: 0.1049 - Char_2_loss: 0.1716 - Char_3_loss: 0.1612 - Char_4_loss: 0.1870 - Char_5_loss: 0.1852 - Char_6_loss: 0.1032 - Char_1_accuracy: 0.9726 - Char_2_accuracy: 0.9473 - Char_3_accuracy: 0.9498 - Char_4_accuracy: 0.9428 - Char_5_accuracy: 0.9425 - Char_6_accuracy: 0.9725 - val_loss: 1.2013 - val_Char_1_loss: 0.1604 - val_Char_2_loss: 0.1775 - val_Char_3_loss: 0.1847 - val_Char_4_loss: 0.2086 - val_Char_5_loss: 0.2604 - val_Char_6_loss: 0.2097 - val_Char_1_accuracy: 0.9460 - val_Char_2_accuracy: 0.9420 - val_Char_3_accuracy: 0.9480 - val_Char_4_accuracy: 0.9340 - val_Char_5_accuracy: 0.9160 - val_Char_6_accuracy: 0.9300\n",
      "Epoch 11/50\n",
      "133/133 [==============================] - 31s 236ms/step - loss: 0.7851 - Char_1_loss: 0.0921 - Char_2_loss: 0.1512 - Char_3_loss: 0.1469 - Char_4_loss: 0.1552 - Char_5_loss: 0.1578 - Char_6_loss: 0.0819 - Char_1_accuracy: 0.9746 - Char_2_accuracy: 0.9514 - Char_3_accuracy: 0.9548 - Char_4_accuracy: 0.9537 - Char_5_accuracy: 0.9514 - Char_6_accuracy: 0.9787 - val_loss: 0.9663 - val_Char_1_loss: 0.1237 - val_Char_2_loss: 0.1588 - val_Char_3_loss: 0.1895 - val_Char_4_loss: 0.1702 - val_Char_5_loss: 0.2519 - val_Char_6_loss: 0.0722 - val_Char_1_accuracy: 0.9620 - val_Char_2_accuracy: 0.9460 - val_Char_3_accuracy: 0.9480 - val_Char_4_accuracy: 0.9420 - val_Char_5_accuracy: 0.9100 - val_Char_6_accuracy: 0.9780\n",
      "Epoch 12/50\n",
      "133/133 [==============================] - 31s 234ms/step - loss: 0.6927 - Char_1_loss: 0.0808 - Char_2_loss: 0.1323 - Char_3_loss: 0.1237 - Char_4_loss: 0.1414 - Char_5_loss: 0.1440 - Char_6_loss: 0.0706 - Char_1_accuracy: 0.9780 - Char_2_accuracy: 0.9582 - Char_3_accuracy: 0.9647 - Char_4_accuracy: 0.9572 - Char_5_accuracy: 0.9552 - Char_6_accuracy: 0.9809 - val_loss: 1.0359 - val_Char_1_loss: 0.1795 - val_Char_2_loss: 0.1533 - val_Char_3_loss: 0.2185 - val_Char_4_loss: 0.1954 - val_Char_5_loss: 0.2144 - val_Char_6_loss: 0.0749 - val_Char_1_accuracy: 0.9420 - val_Char_2_accuracy: 0.9480 - val_Char_3_accuracy: 0.9320 - val_Char_4_accuracy: 0.9460 - val_Char_5_accuracy: 0.9340 - val_Char_6_accuracy: 0.9760\n",
      "Epoch 13/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.6099 - Char_1_loss: 0.0765 - Char_2_loss: 0.1209 - Char_3_loss: 0.1179 - Char_4_loss: 0.1174 - Char_5_loss: 0.1192 - Char_6_loss: 0.0580 - Char_1_accuracy: 0.9766 - Char_2_accuracy: 0.9613 - Char_3_accuracy: 0.9641 - Char_4_accuracy: 0.9631 - Char_5_accuracy: 0.9628 - Char_6_accuracy: 0.9855 - val_loss: 1.2311 - val_Char_1_loss: 0.2290 - val_Char_2_loss: 0.1575 - val_Char_3_loss: 0.2375 - val_Char_4_loss: 0.2111 - val_Char_5_loss: 0.2719 - val_Char_6_loss: 0.1241 - val_Char_1_accuracy: 0.9380 - val_Char_2_accuracy: 0.9520 - val_Char_3_accuracy: 0.9420 - val_Char_4_accuracy: 0.9360 - val_Char_5_accuracy: 0.9080 - val_Char_6_accuracy: 0.9600\n",
      "Epoch 14/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.5430 - Char_1_loss: 0.0597 - Char_2_loss: 0.1116 - Char_3_loss: 0.0984 - Char_4_loss: 0.1058 - Char_5_loss: 0.1133 - Char_6_loss: 0.0541 - Char_1_accuracy: 0.9839 - Char_2_accuracy: 0.9632 - Char_3_accuracy: 0.9684 - Char_4_accuracy: 0.9678 - Char_5_accuracy: 0.9649 - Char_6_accuracy: 0.9860 - val_loss: 2.7809 - val_Char_1_loss: 0.6899 - val_Char_2_loss: 0.2472 - val_Char_3_loss: 0.3112 - val_Char_4_loss: 0.3307 - val_Char_5_loss: 0.5964 - val_Char_6_loss: 0.6056 - val_Char_1_accuracy: 0.8140 - val_Char_2_accuracy: 0.9220 - val_Char_3_accuracy: 0.9040 - val_Char_4_accuracy: 0.9020 - val_Char_5_accuracy: 0.8320 - val_Char_6_accuracy: 0.8060\n",
      "Epoch 15/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.4774 - Char_1_loss: 0.0536 - Char_2_loss: 0.0905 - Char_3_loss: 0.0889 - Char_4_loss: 0.0946 - Char_5_loss: 0.1005 - Char_6_loss: 0.0494 - Char_1_accuracy: 0.9855 - Char_2_accuracy: 0.9726 - Char_3_accuracy: 0.9717 - Char_4_accuracy: 0.9711 - Char_5_accuracy: 0.9699 - Char_6_accuracy: 0.9873 - val_loss: 1.2471 - val_Char_1_loss: 0.2140 - val_Char_2_loss: 0.1462 - val_Char_3_loss: 0.1715 - val_Char_4_loss: 0.2217 - val_Char_5_loss: 0.2698 - val_Char_6_loss: 0.2239 - val_Char_1_accuracy: 0.9360 - val_Char_2_accuracy: 0.9540 - val_Char_3_accuracy: 0.9460 - val_Char_4_accuracy: 0.9300 - val_Char_5_accuracy: 0.9140 - val_Char_6_accuracy: 0.9280\n",
      "Epoch 16/50\n",
      "133/133 [==============================] - 31s 234ms/step - loss: 0.3981 - Char_1_loss: 0.0435 - Char_2_loss: 0.0805 - Char_3_loss: 0.0724 - Char_4_loss: 0.0800 - Char_5_loss: 0.0888 - Char_6_loss: 0.0329 - Char_1_accuracy: 0.9889 - Char_2_accuracy: 0.9759 - Char_3_accuracy: 0.9788 - Char_4_accuracy: 0.9751 - Char_5_accuracy: 0.9740 - Char_6_accuracy: 0.9924 - val_loss: 0.7555 - val_Char_1_loss: 0.0857 - val_Char_2_loss: 0.1329 - val_Char_3_loss: 0.1475 - val_Char_4_loss: 0.1674 - val_Char_5_loss: 0.1676 - val_Char_6_loss: 0.0545 - val_Char_1_accuracy: 0.9800 - val_Char_2_accuracy: 0.9560 - val_Char_3_accuracy: 0.9560 - val_Char_4_accuracy: 0.9460 - val_Char_5_accuracy: 0.9520 - val_Char_6_accuracy: 0.9880\n",
      "Epoch 17/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.3756 - Char_1_loss: 0.0421 - Char_2_loss: 0.0742 - Char_3_loss: 0.0729 - Char_4_loss: 0.0738 - Char_5_loss: 0.0735 - Char_6_loss: 0.0390 - Char_1_accuracy: 0.9878 - Char_2_accuracy: 0.9758 - Char_3_accuracy: 0.9754 - Char_4_accuracy: 0.9768 - Char_5_accuracy: 0.9776 - Char_6_accuracy: 0.9892 - val_loss: 0.5579 - val_Char_1_loss: 0.0603 - val_Char_2_loss: 0.0920 - val_Char_3_loss: 0.1408 - val_Char_4_loss: 0.1114 - val_Char_5_loss: 0.1237 - val_Char_6_loss: 0.0298 - val_Char_1_accuracy: 0.9760 - val_Char_2_accuracy: 0.9680 - val_Char_3_accuracy: 0.9560 - val_Char_4_accuracy: 0.9680 - val_Char_5_accuracy: 0.9680 - val_Char_6_accuracy: 0.9920\n",
      "Epoch 18/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.3270 - Char_1_loss: 0.0339 - Char_2_loss: 0.0590 - Char_3_loss: 0.0605 - Char_4_loss: 0.0693 - Char_5_loss: 0.0742 - Char_6_loss: 0.0301 - Char_1_accuracy: 0.9902 - Char_2_accuracy: 0.9815 - Char_3_accuracy: 0.9806 - Char_4_accuracy: 0.9789 - Char_5_accuracy: 0.9778 - Char_6_accuracy: 0.9932 - val_loss: 0.7260 - val_Char_1_loss: 0.1306 - val_Char_2_loss: 0.0908 - val_Char_3_loss: 0.1505 - val_Char_4_loss: 0.1089 - val_Char_5_loss: 0.1538 - val_Char_6_loss: 0.0914 - val_Char_1_accuracy: 0.9620 - val_Char_2_accuracy: 0.9740 - val_Char_3_accuracy: 0.9500 - val_Char_4_accuracy: 0.9660 - val_Char_5_accuracy: 0.9600 - val_Char_6_accuracy: 0.9780\n",
      "Epoch 19/50\n",
      "133/133 [==============================] - 32s 240ms/step - loss: 0.2944 - Char_1_loss: 0.0327 - Char_2_loss: 0.0626 - Char_3_loss: 0.0547 - Char_4_loss: 0.0563 - Char_5_loss: 0.0611 - Char_6_loss: 0.0269 - Char_1_accuracy: 0.9898 - Char_2_accuracy: 0.9816 - Char_3_accuracy: 0.9820 - Char_4_accuracy: 0.9844 - Char_5_accuracy: 0.9833 - Char_6_accuracy: 0.9935 - val_loss: 0.7973 - val_Char_1_loss: 0.1155 - val_Char_2_loss: 0.1173 - val_Char_3_loss: 0.1556 - val_Char_4_loss: 0.1609 - val_Char_5_loss: 0.1707 - val_Char_6_loss: 0.0774 - val_Char_1_accuracy: 0.9620 - val_Char_2_accuracy: 0.9480 - val_Char_3_accuracy: 0.9520 - val_Char_4_accuracy: 0.9560 - val_Char_5_accuracy: 0.9420 - val_Char_6_accuracy: 0.9720\n",
      "Epoch 20/50\n",
      "133/133 [==============================] - 32s 243ms/step - loss: 0.2693 - Char_1_loss: 0.0333 - Char_2_loss: 0.0539 - Char_3_loss: 0.0500 - Char_4_loss: 0.0546 - Char_5_loss: 0.0547 - Char_6_loss: 0.0227 - Char_1_accuracy: 0.9904 - Char_2_accuracy: 0.9829 - Char_3_accuracy: 0.9842 - Char_4_accuracy: 0.9821 - Char_5_accuracy: 0.9827 - Char_6_accuracy: 0.9954 - val_loss: 0.7438 - val_Char_1_loss: 0.1351 - val_Char_2_loss: 0.0900 - val_Char_3_loss: 0.1568 - val_Char_4_loss: 0.1886 - val_Char_5_loss: 0.1189 - val_Char_6_loss: 0.0545 - val_Char_1_accuracy: 0.9680 - val_Char_2_accuracy: 0.9700 - val_Char_3_accuracy: 0.9480 - val_Char_4_accuracy: 0.9560 - val_Char_5_accuracy: 0.9600 - val_Char_6_accuracy: 0.9780\n",
      "Epoch 21/50\n",
      "133/133 [==============================] - 33s 245ms/step - loss: 0.2615 - Char_1_loss: 0.0289 - Char_2_loss: 0.0528 - Char_3_loss: 0.0428 - Char_4_loss: 0.0542 - Char_5_loss: 0.0583 - Char_6_loss: 0.0245 - Char_1_accuracy: 0.9918 - Char_2_accuracy: 0.9821 - Char_3_accuracy: 0.9875 - Char_4_accuracy: 0.9820 - Char_5_accuracy: 0.9807 - Char_6_accuracy: 0.9945 - val_loss: 0.7186 - val_Char_1_loss: 0.1213 - val_Char_2_loss: 0.1212 - val_Char_3_loss: 0.2084 - val_Char_4_loss: 0.1206 - val_Char_5_loss: 0.1032 - val_Char_6_loss: 0.0439 - val_Char_1_accuracy: 0.9640 - val_Char_2_accuracy: 0.9600 - val_Char_3_accuracy: 0.9360 - val_Char_4_accuracy: 0.9660 - val_Char_5_accuracy: 0.9680 - val_Char_6_accuracy: 0.9860\n",
      "Epoch 22/50\n",
      "133/133 [==============================] - 32s 243ms/step - loss: 0.2170 - Char_1_loss: 0.0230 - Char_2_loss: 0.0440 - Char_3_loss: 0.0371 - Char_4_loss: 0.0484 - Char_5_loss: 0.0446 - Char_6_loss: 0.0198 - Char_1_accuracy: 0.9944 - Char_2_accuracy: 0.9875 - Char_3_accuracy: 0.9882 - Char_4_accuracy: 0.9849 - Char_5_accuracy: 0.9858 - Char_6_accuracy: 0.9958 - val_loss: 0.6423 - val_Char_1_loss: 0.1015 - val_Char_2_loss: 0.0931 - val_Char_3_loss: 0.1586 - val_Char_4_loss: 0.1612 - val_Char_5_loss: 0.0918 - val_Char_6_loss: 0.0362 - val_Char_1_accuracy: 0.9660 - val_Char_2_accuracy: 0.9740 - val_Char_3_accuracy: 0.9520 - val_Char_4_accuracy: 0.9560 - val_Char_5_accuracy: 0.9620 - val_Char_6_accuracy: 0.9880\n",
      "Epoch 23/50\n",
      "133/133 [==============================] - 32s 244ms/step - loss: 0.1997 - Char_1_loss: 0.0233 - Char_2_loss: 0.0397 - Char_3_loss: 0.0356 - Char_4_loss: 0.0422 - Char_5_loss: 0.0406 - Char_6_loss: 0.0182 - Char_1_accuracy: 0.9936 - Char_2_accuracy: 0.9879 - Char_3_accuracy: 0.9888 - Char_4_accuracy: 0.9874 - Char_5_accuracy: 0.9873 - Char_6_accuracy: 0.9959 - val_loss: 0.7052 - val_Char_1_loss: 0.0987 - val_Char_2_loss: 0.1170 - val_Char_3_loss: 0.1429 - val_Char_4_loss: 0.1778 - val_Char_5_loss: 0.1227 - val_Char_6_loss: 0.0461 - val_Char_1_accuracy: 0.9760 - val_Char_2_accuracy: 0.9640 - val_Char_3_accuracy: 0.9520 - val_Char_4_accuracy: 0.9520 - val_Char_5_accuracy: 0.9560 - val_Char_6_accuracy: 0.9800\n",
      "Epoch 24/50\n",
      "133/133 [==============================] - 32s 241ms/step - loss: 0.2106 - Char_1_loss: 0.0217 - Char_2_loss: 0.0411 - Char_3_loss: 0.0373 - Char_4_loss: 0.0464 - Char_5_loss: 0.0426 - Char_6_loss: 0.0216 - Char_1_accuracy: 0.9945 - Char_2_accuracy: 0.9880 - Char_3_accuracy: 0.9889 - Char_4_accuracy: 0.9851 - Char_5_accuracy: 0.9851 - Char_6_accuracy: 0.9944 - val_loss: 0.6798 - val_Char_1_loss: 0.0839 - val_Char_2_loss: 0.1138 - val_Char_3_loss: 0.1554 - val_Char_4_loss: 0.1582 - val_Char_5_loss: 0.1128 - val_Char_6_loss: 0.0557 - val_Char_1_accuracy: 0.9680 - val_Char_2_accuracy: 0.9600 - val_Char_3_accuracy: 0.9440 - val_Char_4_accuracy: 0.9580 - val_Char_5_accuracy: 0.9660 - val_Char_6_accuracy: 0.9800\n",
      "Epoch 25/50\n",
      "133/133 [==============================] - 32s 240ms/step - loss: 0.1961 - Char_1_loss: 0.0199 - Char_2_loss: 0.0430 - Char_3_loss: 0.0354 - Char_4_loss: 0.0456 - Char_5_loss: 0.0359 - Char_6_loss: 0.0164 - Char_1_accuracy: 0.9947 - Char_2_accuracy: 0.9856 - Char_3_accuracy: 0.9876 - Char_4_accuracy: 0.9855 - Char_5_accuracy: 0.9879 - Char_6_accuracy: 0.9961 - val_loss: 0.5970 - val_Char_1_loss: 0.1258 - val_Char_2_loss: 0.1199 - val_Char_3_loss: 0.1081 - val_Char_4_loss: 0.0936 - val_Char_5_loss: 0.1108 - val_Char_6_loss: 0.0388 - val_Char_1_accuracy: 0.9680 - val_Char_2_accuracy: 0.9600 - val_Char_3_accuracy: 0.9700 - val_Char_4_accuracy: 0.9760 - val_Char_5_accuracy: 0.9680 - val_Char_6_accuracy: 0.9880\n",
      "Epoch 26/50\n",
      "133/133 [==============================] - 32s 242ms/step - loss: 0.1695 - Char_1_loss: 0.0202 - Char_2_loss: 0.0365 - Char_3_loss: 0.0289 - Char_4_loss: 0.0318 - Char_5_loss: 0.0359 - Char_6_loss: 0.0162 - Char_1_accuracy: 0.9939 - Char_2_accuracy: 0.9908 - Char_3_accuracy: 0.9908 - Char_4_accuracy: 0.9904 - Char_5_accuracy: 0.9893 - Char_6_accuracy: 0.9961 - val_loss: 0.5900 - val_Char_1_loss: 0.0993 - val_Char_2_loss: 0.0906 - val_Char_3_loss: 0.1150 - val_Char_4_loss: 0.1416 - val_Char_5_loss: 0.0968 - val_Char_6_loss: 0.0468 - val_Char_1_accuracy: 0.9820 - val_Char_2_accuracy: 0.9760 - val_Char_3_accuracy: 0.9700 - val_Char_4_accuracy: 0.9600 - val_Char_5_accuracy: 0.9680 - val_Char_6_accuracy: 0.9840\n",
      "Epoch 27/50\n",
      "133/133 [==============================] - 32s 238ms/step - loss: 0.1767 - Char_1_loss: 0.0186 - Char_2_loss: 0.0400 - Char_3_loss: 0.0257 - Char_4_loss: 0.0416 - Char_5_loss: 0.0336 - Char_6_loss: 0.0173 - Char_1_accuracy: 0.9941 - Char_2_accuracy: 0.9872 - Char_3_accuracy: 0.9921 - Char_4_accuracy: 0.9864 - Char_5_accuracy: 0.9904 - Char_6_accuracy: 0.9958 - val_loss: 0.5551 - val_Char_1_loss: 0.0802 - val_Char_2_loss: 0.1112 - val_Char_3_loss: 0.1048 - val_Char_4_loss: 0.1538 - val_Char_5_loss: 0.0736 - val_Char_6_loss: 0.0314 - val_Char_1_accuracy: 0.9780 - val_Char_2_accuracy: 0.9680 - val_Char_3_accuracy: 0.9740 - val_Char_4_accuracy: 0.9700 - val_Char_5_accuracy: 0.9720 - val_Char_6_accuracy: 0.9840\n",
      "Epoch 28/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.1596 - Char_1_loss: 0.0169 - Char_2_loss: 0.0342 - Char_3_loss: 0.0252 - Char_4_loss: 0.0368 - Char_5_loss: 0.0319 - Char_6_loss: 0.0146 - Char_1_accuracy: 0.9946 - Char_2_accuracy: 0.9906 - Char_3_accuracy: 0.9916 - Char_4_accuracy: 0.9891 - Char_5_accuracy: 0.9901 - Char_6_accuracy: 0.9965 - val_loss: 0.6890 - val_Char_1_loss: 0.0899 - val_Char_2_loss: 0.1210 - val_Char_3_loss: 0.1747 - val_Char_4_loss: 0.1469 - val_Char_5_loss: 0.1173 - val_Char_6_loss: 0.0391 - val_Char_1_accuracy: 0.9740 - val_Char_2_accuracy: 0.9640 - val_Char_3_accuracy: 0.9640 - val_Char_4_accuracy: 0.9600 - val_Char_5_accuracy: 0.9720 - val_Char_6_accuracy: 0.9840\n",
      "Epoch 29/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.1514 - Char_1_loss: 0.0160 - Char_2_loss: 0.0307 - Char_3_loss: 0.0277 - Char_4_loss: 0.0312 - Char_5_loss: 0.0307 - Char_6_loss: 0.0151 - Char_1_accuracy: 0.9955 - Char_2_accuracy: 0.9919 - Char_3_accuracy: 0.9915 - Char_4_accuracy: 0.9911 - Char_5_accuracy: 0.9912 - Char_6_accuracy: 0.9965 - val_loss: 0.8251 - val_Char_1_loss: 0.2025 - val_Char_2_loss: 0.0936 - val_Char_3_loss: 0.1853 - val_Char_4_loss: 0.1272 - val_Char_5_loss: 0.1422 - val_Char_6_loss: 0.0743 - val_Char_1_accuracy: 0.9460 - val_Char_2_accuracy: 0.9720 - val_Char_3_accuracy: 0.9460 - val_Char_4_accuracy: 0.9660 - val_Char_5_accuracy: 0.9600 - val_Char_6_accuracy: 0.9740\n",
      "Epoch 30/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.1396 - Char_1_loss: 0.0173 - Char_2_loss: 0.0310 - Char_3_loss: 0.0251 - Char_4_loss: 0.0299 - Char_5_loss: 0.0249 - Char_6_loss: 0.0114 - Char_1_accuracy: 0.9954 - Char_2_accuracy: 0.9915 - Char_3_accuracy: 0.9911 - Char_4_accuracy: 0.9909 - Char_5_accuracy: 0.9931 - Char_6_accuracy: 0.9981 - val_loss: 0.8631 - val_Char_1_loss: 0.1392 - val_Char_2_loss: 0.1258 - val_Char_3_loss: 0.2025 - val_Char_4_loss: 0.1399 - val_Char_5_loss: 0.1287 - val_Char_6_loss: 0.1271 - val_Char_1_accuracy: 0.9540 - val_Char_2_accuracy: 0.9660 - val_Char_3_accuracy: 0.9420 - val_Char_4_accuracy: 0.9600 - val_Char_5_accuracy: 0.9640 - val_Char_6_accuracy: 0.9540\n",
      "Epoch 31/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.1313 - Char_1_loss: 0.0132 - Char_2_loss: 0.0296 - Char_3_loss: 0.0217 - Char_4_loss: 0.0239 - Char_5_loss: 0.0288 - Char_6_loss: 0.0141 - Char_1_accuracy: 0.9967 - Char_2_accuracy: 0.9919 - Char_3_accuracy: 0.9933 - Char_4_accuracy: 0.9931 - Char_5_accuracy: 0.9909 - Char_6_accuracy: 0.9964 - val_loss: 0.6998 - val_Char_1_loss: 0.1094 - val_Char_2_loss: 0.1173 - val_Char_3_loss: 0.2004 - val_Char_4_loss: 0.1395 - val_Char_5_loss: 0.0926 - val_Char_6_loss: 0.0406 - val_Char_1_accuracy: 0.9720 - val_Char_2_accuracy: 0.9620 - val_Char_3_accuracy: 0.9480 - val_Char_4_accuracy: 0.9700 - val_Char_5_accuracy: 0.9720 - val_Char_6_accuracy: 0.9840\n",
      "Epoch 32/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.1303 - Char_1_loss: 0.0130 - Char_2_loss: 0.0273 - Char_3_loss: 0.0230 - Char_4_loss: 0.0291 - Char_5_loss: 0.0259 - Char_6_loss: 0.0120 - Char_1_accuracy: 0.9968 - Char_2_accuracy: 0.9915 - Char_3_accuracy: 0.9928 - Char_4_accuracy: 0.9900 - Char_5_accuracy: 0.9922 - Char_6_accuracy: 0.9976 - val_loss: 1.3019 - val_Char_1_loss: 0.2914 - val_Char_2_loss: 0.1709 - val_Char_3_loss: 0.2394 - val_Char_4_loss: 0.1524 - val_Char_5_loss: 0.2723 - val_Char_6_loss: 0.1754 - val_Char_1_accuracy: 0.9160 - val_Char_2_accuracy: 0.9480 - val_Char_3_accuracy: 0.9380 - val_Char_4_accuracy: 0.9500 - val_Char_5_accuracy: 0.9120 - val_Char_6_accuracy: 0.9460\n",
      "Epoch 33/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.1353 - Char_1_loss: 0.0134 - Char_2_loss: 0.0288 - Char_3_loss: 0.0249 - Char_4_loss: 0.0277 - Char_5_loss: 0.0261 - Char_6_loss: 0.0144 - Char_1_accuracy: 0.9967 - Char_2_accuracy: 0.9931 - Char_3_accuracy: 0.9925 - Char_4_accuracy: 0.9918 - Char_5_accuracy: 0.9920 - Char_6_accuracy: 0.9968 - val_loss: 1.0788 - val_Char_1_loss: 0.1880 - val_Char_2_loss: 0.1588 - val_Char_3_loss: 0.1598 - val_Char_4_loss: 0.1560 - val_Char_5_loss: 0.1984 - val_Char_6_loss: 0.2179 - val_Char_1_accuracy: 0.9420 - val_Char_2_accuracy: 0.9560 - val_Char_3_accuracy: 0.9560 - val_Char_4_accuracy: 0.9560 - val_Char_5_accuracy: 0.9420 - val_Char_6_accuracy: 0.9380\n",
      "Epoch 34/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.1250 - Char_1_loss: 0.0119 - Char_2_loss: 0.0254 - Char_3_loss: 0.0198 - Char_4_loss: 0.0278 - Char_5_loss: 0.0263 - Char_6_loss: 0.0138 - Char_1_accuracy: 0.9973 - Char_2_accuracy: 0.9925 - Char_3_accuracy: 0.9929 - Char_4_accuracy: 0.9916 - Char_5_accuracy: 0.9921 - Char_6_accuracy: 0.9960 - val_loss: 0.6919 - val_Char_1_loss: 0.1096 - val_Char_2_loss: 0.1178 - val_Char_3_loss: 0.1292 - val_Char_4_loss: 0.1338 - val_Char_5_loss: 0.1585 - val_Char_6_loss: 0.0429 - val_Char_1_accuracy: 0.9700 - val_Char_2_accuracy: 0.9620 - val_Char_3_accuracy: 0.9720 - val_Char_4_accuracy: 0.9700 - val_Char_5_accuracy: 0.9580 - val_Char_6_accuracy: 0.9860\n",
      "Epoch 35/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.1214 - Char_1_loss: 0.0138 - Char_2_loss: 0.0276 - Char_3_loss: 0.0198 - Char_4_loss: 0.0241 - Char_5_loss: 0.0252 - Char_6_loss: 0.0109 - Char_1_accuracy: 0.9965 - Char_2_accuracy: 0.9913 - Char_3_accuracy: 0.9939 - Char_4_accuracy: 0.9914 - Char_5_accuracy: 0.9927 - Char_6_accuracy: 0.9978 - val_loss: 0.6352 - val_Char_1_loss: 0.1265 - val_Char_2_loss: 0.1054 - val_Char_3_loss: 0.0942 - val_Char_4_loss: 0.1590 - val_Char_5_loss: 0.1328 - val_Char_6_loss: 0.0173 - val_Char_1_accuracy: 0.9800 - val_Char_2_accuracy: 0.9680 - val_Char_3_accuracy: 0.9760 - val_Char_4_accuracy: 0.9600 - val_Char_5_accuracy: 0.9560 - val_Char_6_accuracy: 0.9940\n",
      "Epoch 36/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.1048 - Char_1_loss: 0.0111 - Char_2_loss: 0.0228 - Char_3_loss: 0.0183 - Char_4_loss: 0.0244 - Char_5_loss: 0.0184 - Char_6_loss: 0.0099 - Char_1_accuracy: 0.9972 - Char_2_accuracy: 0.9934 - Char_3_accuracy: 0.9944 - Char_4_accuracy: 0.9931 - Char_5_accuracy: 0.9955 - Char_6_accuracy: 0.9979 - val_loss: 0.5381 - val_Char_1_loss: 0.0778 - val_Char_2_loss: 0.1067 - val_Char_3_loss: 0.0933 - val_Char_4_loss: 0.1614 - val_Char_5_loss: 0.0670 - val_Char_6_loss: 0.0318 - val_Char_1_accuracy: 0.9840 - val_Char_2_accuracy: 0.9760 - val_Char_3_accuracy: 0.9720 - val_Char_4_accuracy: 0.9720 - val_Char_5_accuracy: 0.9760 - val_Char_6_accuracy: 0.9900\n",
      "Epoch 37/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.1161 - Char_1_loss: 0.0110 - Char_2_loss: 0.0271 - Char_3_loss: 0.0177 - Char_4_loss: 0.0244 - Char_5_loss: 0.0209 - Char_6_loss: 0.0149 - Char_1_accuracy: 0.9973 - Char_2_accuracy: 0.9922 - Char_3_accuracy: 0.9945 - Char_4_accuracy: 0.9933 - Char_5_accuracy: 0.9944 - Char_6_accuracy: 0.9978 - val_loss: 0.8150 - val_Char_1_loss: 0.1232 - val_Char_2_loss: 0.1161 - val_Char_3_loss: 0.1593 - val_Char_4_loss: 0.2000 - val_Char_5_loss: 0.1153 - val_Char_6_loss: 0.1012 - val_Char_1_accuracy: 0.9680 - val_Char_2_accuracy: 0.9700 - val_Char_3_accuracy: 0.9560 - val_Char_4_accuracy: 0.9560 - val_Char_5_accuracy: 0.9680 - val_Char_6_accuracy: 0.9660\n",
      "Epoch 38/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.0993 - Char_1_loss: 0.0098 - Char_2_loss: 0.0239 - Char_3_loss: 0.0133 - Char_4_loss: 0.0238 - Char_5_loss: 0.0168 - Char_6_loss: 0.0116 - Char_1_accuracy: 0.9975 - Char_2_accuracy: 0.9934 - Char_3_accuracy: 0.9965 - Char_4_accuracy: 0.9927 - Char_5_accuracy: 0.9956 - Char_6_accuracy: 0.9975 - val_loss: 0.7346 - val_Char_1_loss: 0.1375 - val_Char_2_loss: 0.0989 - val_Char_3_loss: 0.1891 - val_Char_4_loss: 0.1555 - val_Char_5_loss: 0.0894 - val_Char_6_loss: 0.0643 - val_Char_1_accuracy: 0.9600 - val_Char_2_accuracy: 0.9720 - val_Char_3_accuracy: 0.9520 - val_Char_4_accuracy: 0.9720 - val_Char_5_accuracy: 0.9780 - val_Char_6_accuracy: 0.9860\n",
      "Epoch 39/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.1149 - Char_1_loss: 0.0137 - Char_2_loss: 0.0261 - Char_3_loss: 0.0161 - Char_4_loss: 0.0243 - Char_5_loss: 0.0223 - Char_6_loss: 0.0124 - Char_1_accuracy: 0.9960 - Char_2_accuracy: 0.9935 - Char_3_accuracy: 0.9944 - Char_4_accuracy: 0.9928 - Char_5_accuracy: 0.9945 - Char_6_accuracy: 0.9975 - val_loss: 0.8290 - val_Char_1_loss: 0.1212 - val_Char_2_loss: 0.1579 - val_Char_3_loss: 0.1312 - val_Char_4_loss: 0.2194 - val_Char_5_loss: 0.1215 - val_Char_6_loss: 0.0778 - val_Char_1_accuracy: 0.9720 - val_Char_2_accuracy: 0.9680 - val_Char_3_accuracy: 0.9660 - val_Char_4_accuracy: 0.9620 - val_Char_5_accuracy: 0.9660 - val_Char_6_accuracy: 0.9760\n",
      "Epoch 40/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.1200 - Char_1_loss: 0.0161 - Char_2_loss: 0.0238 - Char_3_loss: 0.0173 - Char_4_loss: 0.0212 - Char_5_loss: 0.0254 - Char_6_loss: 0.0162 - Char_1_accuracy: 0.9956 - Char_2_accuracy: 0.9928 - Char_3_accuracy: 0.9946 - Char_4_accuracy: 0.9941 - Char_5_accuracy: 0.9925 - Char_6_accuracy: 0.9955 - val_loss: 0.7446 - val_Char_1_loss: 0.1164 - val_Char_2_loss: 0.1503 - val_Char_3_loss: 0.1487 - val_Char_4_loss: 0.1347 - val_Char_5_loss: 0.1663 - val_Char_6_loss: 0.0282 - val_Char_1_accuracy: 0.9680 - val_Char_2_accuracy: 0.9580 - val_Char_3_accuracy: 0.9700 - val_Char_4_accuracy: 0.9700 - val_Char_5_accuracy: 0.9680 - val_Char_6_accuracy: 0.9920\n",
      "Epoch 41/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.1220 - Char_1_loss: 0.0150 - Char_2_loss: 0.0208 - Char_3_loss: 0.0171 - Char_4_loss: 0.0245 - Char_5_loss: 0.0318 - Char_6_loss: 0.0128 - Char_1_accuracy: 0.9958 - Char_2_accuracy: 0.9942 - Char_3_accuracy: 0.9946 - Char_4_accuracy: 0.9939 - Char_5_accuracy: 0.9891 - Char_6_accuracy: 0.9969 - val_loss: 0.7347 - val_Char_1_loss: 0.1553 - val_Char_2_loss: 0.1015 - val_Char_3_loss: 0.1215 - val_Char_4_loss: 0.1400 - val_Char_5_loss: 0.1462 - val_Char_6_loss: 0.0702 - val_Char_1_accuracy: 0.9720 - val_Char_2_accuracy: 0.9760 - val_Char_3_accuracy: 0.9700 - val_Char_4_accuracy: 0.9700 - val_Char_5_accuracy: 0.9580 - val_Char_6_accuracy: 0.9840\n",
      "Epoch 42/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.1021 - Char_1_loss: 0.0106 - Char_2_loss: 0.0205 - Char_3_loss: 0.0167 - Char_4_loss: 0.0198 - Char_5_loss: 0.0227 - Char_6_loss: 0.0117 - Char_1_accuracy: 0.9972 - Char_2_accuracy: 0.9946 - Char_3_accuracy: 0.9944 - Char_4_accuracy: 0.9953 - Char_5_accuracy: 0.9944 - Char_6_accuracy: 0.9978 - val_loss: 0.6144 - val_Char_1_loss: 0.1306 - val_Char_2_loss: 0.0821 - val_Char_3_loss: 0.1308 - val_Char_4_loss: 0.1411 - val_Char_5_loss: 0.0996 - val_Char_6_loss: 0.0302 - val_Char_1_accuracy: 0.9820 - val_Char_2_accuracy: 0.9740 - val_Char_3_accuracy: 0.9680 - val_Char_4_accuracy: 0.9680 - val_Char_5_accuracy: 0.9780 - val_Char_6_accuracy: 0.9900\n",
      "Epoch 43/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.0939 - Char_1_loss: 0.0105 - Char_2_loss: 0.0196 - Char_3_loss: 0.0149 - Char_4_loss: 0.0203 - Char_5_loss: 0.0181 - Char_6_loss: 0.0104 - Char_1_accuracy: 0.9967 - Char_2_accuracy: 0.9946 - Char_3_accuracy: 0.9958 - Char_4_accuracy: 0.9946 - Char_5_accuracy: 0.9951 - Char_6_accuracy: 0.9974 - val_loss: 0.6149 - val_Char_1_loss: 0.1360 - val_Char_2_loss: 0.0770 - val_Char_3_loss: 0.1052 - val_Char_4_loss: 0.1781 - val_Char_5_loss: 0.0760 - val_Char_6_loss: 0.0426 - val_Char_1_accuracy: 0.9680 - val_Char_2_accuracy: 0.9700 - val_Char_3_accuracy: 0.9660 - val_Char_4_accuracy: 0.9640 - val_Char_5_accuracy: 0.9800 - val_Char_6_accuracy: 0.9860\n",
      "Epoch 44/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.0944 - Char_1_loss: 0.0110 - Char_2_loss: 0.0240 - Char_3_loss: 0.0127 - Char_4_loss: 0.0165 - Char_5_loss: 0.0207 - Char_6_loss: 0.0095 - Char_1_accuracy: 0.9971 - Char_2_accuracy: 0.9947 - Char_3_accuracy: 0.9964 - Char_4_accuracy: 0.9958 - Char_5_accuracy: 0.9944 - Char_6_accuracy: 0.9987 - val_loss: 0.9980 - val_Char_1_loss: 0.1757 - val_Char_2_loss: 0.1535 - val_Char_3_loss: 0.1370 - val_Char_4_loss: 0.2232 - val_Char_5_loss: 0.1762 - val_Char_6_loss: 0.1323 - val_Char_1_accuracy: 0.9620 - val_Char_2_accuracy: 0.9580 - val_Char_3_accuracy: 0.9560 - val_Char_4_accuracy: 0.9600 - val_Char_5_accuracy: 0.9500 - val_Char_6_accuracy: 0.9680\n",
      "Epoch 45/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.0857 - Char_1_loss: 0.0078 - Char_2_loss: 0.0210 - Char_3_loss: 0.0118 - Char_4_loss: 0.0161 - Char_5_loss: 0.0183 - Char_6_loss: 0.0107 - Char_1_accuracy: 0.9984 - Char_2_accuracy: 0.9958 - Char_3_accuracy: 0.9966 - Char_4_accuracy: 0.9959 - Char_5_accuracy: 0.9949 - Char_6_accuracy: 0.9985 - val_loss: 0.7324 - val_Char_1_loss: 0.1597 - val_Char_2_loss: 0.1000 - val_Char_3_loss: 0.1363 - val_Char_4_loss: 0.1585 - val_Char_5_loss: 0.1118 - val_Char_6_loss: 0.0660 - val_Char_1_accuracy: 0.9680 - val_Char_2_accuracy: 0.9760 - val_Char_3_accuracy: 0.9700 - val_Char_4_accuracy: 0.9700 - val_Char_5_accuracy: 0.9720 - val_Char_6_accuracy: 0.9820\n",
      "Epoch 46/50\n",
      "133/133 [==============================] - 31s 236ms/step - loss: 0.0806 - Char_1_loss: 0.0108 - Char_2_loss: 0.0158 - Char_3_loss: 0.0131 - Char_4_loss: 0.0163 - Char_5_loss: 0.0149 - Char_6_loss: 0.0098 - Char_1_accuracy: 0.9972 - Char_2_accuracy: 0.9961 - Char_3_accuracy: 0.9958 - Char_4_accuracy: 0.9955 - Char_5_accuracy: 0.9961 - Char_6_accuracy: 0.9980 - val_loss: 1.0769 - val_Char_1_loss: 0.2428 - val_Char_2_loss: 0.1629 - val_Char_3_loss: 0.1823 - val_Char_4_loss: 0.2142 - val_Char_5_loss: 0.1641 - val_Char_6_loss: 0.1105 - val_Char_1_accuracy: 0.9560 - val_Char_2_accuracy: 0.9620 - val_Char_3_accuracy: 0.9540 - val_Char_4_accuracy: 0.9420 - val_Char_5_accuracy: 0.9560 - val_Char_6_accuracy: 0.9600\n",
      "Epoch 47/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.0958 - Char_1_loss: 0.0099 - Char_2_loss: 0.0202 - Char_3_loss: 0.0126 - Char_4_loss: 0.0193 - Char_5_loss: 0.0200 - Char_6_loss: 0.0138 - Char_1_accuracy: 0.9981 - Char_2_accuracy: 0.9942 - Char_3_accuracy: 0.9954 - Char_4_accuracy: 0.9954 - Char_5_accuracy: 0.9940 - Char_6_accuracy: 0.9971 - val_loss: 0.6454 - val_Char_1_loss: 0.0775 - val_Char_2_loss: 0.0913 - val_Char_3_loss: 0.1467 - val_Char_4_loss: 0.1849 - val_Char_5_loss: 0.1124 - val_Char_6_loss: 0.0326 - val_Char_1_accuracy: 0.9860 - val_Char_2_accuracy: 0.9780 - val_Char_3_accuracy: 0.9740 - val_Char_4_accuracy: 0.9620 - val_Char_5_accuracy: 0.9660 - val_Char_6_accuracy: 0.9900\n",
      "Epoch 48/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.0950 - Char_1_loss: 0.0091 - Char_2_loss: 0.0239 - Char_3_loss: 0.0111 - Char_4_loss: 0.0170 - Char_5_loss: 0.0213 - Char_6_loss: 0.0126 - Char_1_accuracy: 0.9978 - Char_2_accuracy: 0.9942 - Char_3_accuracy: 0.9973 - Char_4_accuracy: 0.9956 - Char_5_accuracy: 0.9928 - Char_6_accuracy: 0.9973 - val_loss: 0.7618 - val_Char_1_loss: 0.1462 - val_Char_2_loss: 0.1313 - val_Char_3_loss: 0.1661 - val_Char_4_loss: 0.1709 - val_Char_5_loss: 0.1087 - val_Char_6_loss: 0.0385 - val_Char_1_accuracy: 0.9720 - val_Char_2_accuracy: 0.9680 - val_Char_3_accuracy: 0.9760 - val_Char_4_accuracy: 0.9720 - val_Char_5_accuracy: 0.9680 - val_Char_6_accuracy: 0.9840\n",
      "Epoch 49/50\n",
      "133/133 [==============================] - 31s 235ms/step - loss: 0.1067 - Char_1_loss: 0.0137 - Char_2_loss: 0.0218 - Char_3_loss: 0.0172 - Char_4_loss: 0.0225 - Char_5_loss: 0.0199 - Char_6_loss: 0.0116 - Char_1_accuracy: 0.9965 - Char_2_accuracy: 0.9947 - Char_3_accuracy: 0.9944 - Char_4_accuracy: 0.9929 - Char_5_accuracy: 0.9942 - Char_6_accuracy: 0.9975 - val_loss: 0.7958 - val_Char_1_loss: 0.1164 - val_Char_2_loss: 0.1064 - val_Char_3_loss: 0.2003 - val_Char_4_loss: 0.1688 - val_Char_5_loss: 0.1287 - val_Char_6_loss: 0.0752 - val_Char_1_accuracy: 0.9720 - val_Char_2_accuracy: 0.9760 - val_Char_3_accuracy: 0.9660 - val_Char_4_accuracy: 0.9620 - val_Char_5_accuracy: 0.9720 - val_Char_6_accuracy: 0.9720\n",
      "Epoch 50/50\n",
      "133/133 [==============================] - 32s 240ms/step - loss: 0.1031 - Char_1_loss: 0.0123 - Char_2_loss: 0.0221 - Char_3_loss: 0.0162 - Char_4_loss: 0.0232 - Char_5_loss: 0.0169 - Char_6_loss: 0.0124 - Char_1_accuracy: 0.9966 - Char_2_accuracy: 0.9949 - Char_3_accuracy: 0.9944 - Char_4_accuracy: 0.9946 - Char_5_accuracy: 0.9953 - Char_6_accuracy: 0.9971 - val_loss: 0.7355 - val_Char_1_loss: 0.1305 - val_Char_2_loss: 0.1116 - val_Char_3_loss: 0.1465 - val_Char_4_loss: 0.1561 - val_Char_5_loss: 0.1197 - val_Char_6_loss: 0.0712 - val_Char_1_accuracy: 0.9720 - val_Char_2_accuracy: 0.9700 - val_Char_3_accuracy: 0.9720 - val_Char_4_accuracy: 0.9620 - val_Char_5_accuracy: 0.9740 - val_Char_6_accuracy: 0.9860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26b50e68690>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchsize = 64 \n",
    "numbatches = math.ceil(numtrain / batchsize)\n",
    "\n",
    "checkpointfreq = 10 # Saves every this many epochs\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"myweights1\",\n",
    "    save_freq=numbatches * checkpointfreq,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# Use this callback when fitting the model\n",
    "\n",
    "model.fit(train_images, [train_labels1, train_labels2, train_labels3,\n",
    "                        train_labels4, train_labels5, train_labels6],\n",
    "                        validation_data=(val_images, [\n",
    "                        val_labels1, val_labels2, val_labels3,\n",
    "                        val_labels4, val_labels5, val_labels6\n",
    "                        ]),\n",
    "                        batch_size=batchsize,\n",
    "                        epochs=50,\n",
    "                        callbacks=[ model_checkpoint_callback])\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('myweights2') \n",
    "#Use this to save weights.  Weights are saved after every 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fdb45c453a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('myweights2')\n",
    "#Use this to load pre-trained weights or a checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below here, put your function for taking the output of the model on a given image and returning a string.  Pass an image to the function.\n",
    "\n",
    "For example, suppose we pass training image 0_vgxrub.jpeg to the model, and get an output of 6*21.  We pass this output to the function (along with the dictionary defined in the first cell), and it should return the string containing each of the six characters.  In this case, it would return VGXRUB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 230ms/step\n",
      "[2.5619982e-13 8.5067728e-13 3.0486895e-15 5.3489178e-17 2.4479086e-06\n",
      " 8.8473125e-06 7.1948057e-13 1.1266514e-18 1.1501089e-11 1.5017595e-11\n",
      " 3.0547284e-17 9.3950942e-17 6.3397266e-16 1.1585654e-15 9.9379715e-17\n",
      " 6.3864413e-12 1.1671641e-12 9.9998868e-01 3.2650993e-12 1.9514841e-16\n",
      " 3.8804403e-13]\n"
     ]
    }
   ],
   "source": [
    "# Example of how to pass a particular image to the model\n",
    "\n",
    "test1 = np.expand_dims(train_images[0],0)\n",
    "outtest1 = model.predict(test1)\n",
    "\n",
    "\n",
    "# The first character's output, for example, is \n",
    "print(outtest1[0][0])\n",
    "\n",
    "\n",
    "# Look at which entry has the largest value (probability).  \n",
    "\n",
    "\n",
    "\n",
    "# Your function should go here:\n",
    "\n",
    "def ConvertOutput(output, dictionary):\n",
    "    string = \"\"\n",
    "    output = np.array(output)\n",
    "    output = output.reshape((6, 21))\n",
    "    for i in range(6):\n",
    "        char_index = np.argmax(output[i])\n",
    "        char = dictionary[char_index]\n",
    "        string += char\n",
    "\n",
    "    return string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABHCP6\n"
     ]
    }
   ],
   "source": [
    "print(ConvertOutput(outtest1, dict1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below here is stuff for testing the model.  Don't run this code.  Leave it commented out for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfiles2 = os.listdir('./valdata/')\n",
    "testfiles = [f for f in testfiles2 if os.path.isfile('.' +'/valdata/' + f)]\n",
    "\n",
    "numtest = len(testfiles)\n",
    "\n",
    "test_images = np.zeros((numtest,250,50))\n",
    "test_labels = np.zeros((numtest,6,21))\n",
    "test_labels1 = np.zeros((numtest, 21))\n",
    "test_labels2 = np.zeros((numtest, 21))\n",
    "test_labels3 = np.zeros((numtest, 21))\n",
    "test_labels4 = np.zeros((numtest, 21))\n",
    "test_labels5 = np.zeros((numtest, 21))\n",
    "test_labels6 = np.zeros((numtest, 21))\n",
    "test_numlist = np.zeros((numtest))\n",
    "test_letters = ['     '] * numtest\n",
    "\n",
    "\n",
    "\n",
    "for i in range(numtest):\n",
    "    img = Image.open('./valdata/' + testfiles[i]).convert('L')\n",
    "    data = np.transpose(np.asarray(img)) / 255\n",
    "    test_images[i] = data\n",
    "    test_numlist[i] = re.split(r\"[_.]\", testfiles[i])[0]\n",
    "    temp = re.split(r\"[_.]\", testfiles[i])\n",
    "    test_labels[i] = OneHotConverter(temp[1], dict2)\n",
    "    test_labels1[i] = test_labels[i][0]\n",
    "    test_labels2[i] = test_labels[i][1]\n",
    "    test_labels3[i] = test_labels[i][2]\n",
    "    test_labels4[i] = test_labels[i][3]\n",
    "    test_labels5[i] = test_labels[i][4]\n",
    "    test_labels6[i] = test_labels[i][5]\n",
    "    test_letters[i] = temp[1].upper()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 6s 271ms/step - loss: 0.7355 - Char_1_loss: 0.1305 - Char_2_loss: 0.1116 - Char_3_loss: 0.1465 - Char_4_loss: 0.1561 - Char_5_loss: 0.1197 - Char_6_loss: 0.0712 - Char_1_accuracy: 0.9720 - Char_2_accuracy: 0.9700 - Char_3_accuracy: 0.9720 - Char_4_accuracy: 0.9620 - Char_5_accuracy: 0.9740 - Char_6_accuracy: 0.9860\n",
      "Average character accuracy on test set: 97.27 percent\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_images, [test_labels1, test_labels2, test_labels3,\n",
    "                        test_labels4, test_labels5, test_labels6])\n",
    "avgaccuracy = 100*sum(results[-6:])/6 \n",
    "\n",
    "\n",
    "print(f\"Average character accuracy on test set: {avgaccuracy:.2f} percent\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfiles2 = os.listdir('./testdata/')\n",
    "testfiles = [f for f in testfiles2 if os.path.isfile('.' +'/testdata/' + f)]\n",
    "\n",
    "numtest = len(testfiles)\n",
    "\n",
    "test_images = np.zeros((numtest,250,50))\n",
    "test_labels = np.zeros((numtest,6,21))\n",
    "test_labels1 = np.zeros((numtest, 21))\n",
    "test_labels2 = np.zeros((numtest, 21))\n",
    "test_labels3 = np.zeros((numtest, 21))\n",
    "test_labels4 = np.zeros((numtest, 21))\n",
    "test_labels5 = np.zeros((numtest, 21))\n",
    "test_labels6 = np.zeros((numtest, 21))\n",
    "test_numlist = np.zeros((numtest))\n",
    "test_letters = ['     '] * numtest\n",
    "\n",
    "\n",
    "\n",
    "for i in range(numtest):\n",
    "    img = Image.open('./testdata/' + testfiles[i]).convert('L')\n",
    "    data = np.transpose(np.asarray(img)) / 255\n",
    "    test_images[i] = data\n",
    "    test_numlist[i] = re.split(r\"[_.]\", testfiles[i])[0]\n",
    "    temp = re.split(r\"[_.]\", testfiles[i])\n",
    "    test_labels[i] = OneHotConverter(temp[1], dict2)\n",
    "    test_labels1[i] = test_labels[i][0]\n",
    "    test_labels2[i] = test_labels[i][1]\n",
    "    test_labels3[i] = test_labels[i][2]\n",
    "    test_labels4[i] = test_labels[i][3]\n",
    "    test_labels5[i] = test_labels[i][4]\n",
    "    test_labels6[i] = test_labels[i][5]\n",
    "    test_letters[i] = temp[1].upper()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 8s 243ms/step - loss: 0.7900 - Char_1_loss: 0.0814 - Char_2_loss: 0.1569 - Char_3_loss: 0.1324 - Char_4_loss: 0.2050 - Char_5_loss: 0.1301 - Char_6_loss: 0.0842 - Char_1_accuracy: 0.9810 - Char_2_accuracy: 0.9660 - Char_3_accuracy: 0.9770 - Char_4_accuracy: 0.9570 - Char_5_accuracy: 0.9720 - Char_6_accuracy: 0.9790\n",
      "Average character accuracy on test set: 97.20 percent\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_images, [test_labels1, test_labels2, test_labels3,\n",
    "                        test_labels4, test_labels5, test_labels6])\n",
    "avgaccuracy = 100*sum(results[-6:])/6 \n",
    "\n",
    "\n",
    "print(f\"Average character accuracy on test set: {avgaccuracy:.2f} percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
